사소하지만 메모하는 습관을 만들고,

12시 현재 커피마시면서 유튭을 보는데
이런 시선분산하는 요소가 많다.

50분을 소비한것같다.


필요없는 LWR 코드 정리 & ( done)
LWR 전략 만들기

LSTM 전략 만들기.


모두의 눈이 높아졌다라면,
그건 시대가 변한거다.

근데,,, LWR 수식 이해가 안간다...

중국인 코드 h도 결국엔 h가 만들어진 수식에 따라서 modeling하는거고.
그 weight를 주는 8지점은 계속변경해야하는거니깐 이걸 코드로 조금 변경하면 될듯한데
x = np.array(X1.loc[[8]].values)
theta = lwl_regression(x, training_X, training_Y, LS=True)  
+
인도인 코드 각 지점을 이렇게 주면
prediction = [local_regression(x0, X, Y, tau) for x0 in domain]


지금 고민하고있는것은 
Multivariable을 활용하기 위해서 
어떻게 x 변수를 늘릴 수 있을까 고민하고 있는 것이다. 그리고 중국인 코드와 인도인 코들들 합체시키면 
locally weight가 계산되지 않을까 싶은거다.




그런데.. theta가 계산된다면 

Linear regression은 sklearn으로해서 forecast가 되는데, 
LWR은 Local 이라는 특성으로 predict 가 안된다.. 뭐 이런 개떡같은 경우가...
그럼 논문 저자는 어떻게 predict한거지?
https://stats.stackexchange.com/questions/27103/extrapolating-a-lowess-model


1-D로 인풋을 넣어주면 되는거같은데 음.. (?) 확신이 안서고,,
https://stackoverflow.com/questions/36252434/predicting-on-new-data-using-locally-weighted-regression-loess-lowess

2-D로 하게되면 2가지 문제점이 있다.
1) 일단 extrapolation으로 알고리즘이 안되는 것과.
    즉 주어진 데이터 셋에서 예측한다는게 사실 잘 이해안간다.
    from skmisc.loess import loess 이걸 사용한 예제와.
ValueError: b'Extrapolation not allowed with blending'
2) Dimension문제
    https://www.statsmodels.org/stable/generated/statsmodels.nonparametric.smoothers_lowess.lowess.html

3) 결국 중국인 예제도 
https://github.com/slydg/Locally-weighted-linear-regression-/blob/master/dependency.py
2개를 사용해서 새로운 Formula를 만들고 거기에 newX를 넣어서 새로운 값이 계산해보는걸 하지만 이건 시도해보지 않았다.



어떻게 해야하지..
그냥 일단 LWR은 1개 input으로 prediction하는걸 해볼까..
Multivariable regression이 안되는 건가?




부동산 얘기
라고 할때 빚내서 집 샀어야 했는데....(70년대), 라고 할때 빚내서 집 샀어야 했는데....(80년대), 라고 할때 그냥 샀어야 했는데....(90년대), 라고 할때 정부 말 믿고 집 샀어야 했는데....(2000년대), 라고 할때 주저하지 말고 집 샀어야 했는데....(2010년대), 라고 뒤안돌아보고 집 샀어야 했는데....(5년전), 라고 할때 질렀어야 했는데....(3년전), 라고 할때 미친척하고 샀어야 했는데....(1년전), 라고 할때 정부 말 믿지말고 살껄 ㅠ_ㅠ(1년후) // 무주택자들 무한반복 ㅎㅎ



이제 서울 아파트 최소 15억이다 ㅋㅋㅋ 그이하로는 한채도 안판다 ㅋㅋㅋㅋ 세금 상승만큼 월세올려야지 ㅋㅋㅋㅋ
