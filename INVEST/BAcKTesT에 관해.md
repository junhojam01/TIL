일단 저는 전혀 인공지능 관련해서 전문가가 아닙니다. 그냥 논문에서 나온걸 이것저것 시도 해본 일반적인 사람입니다. 딥러닝 관련해서는 총알이 없어서 직접적으로 실험결과도 못봅니다. 그래도 보통 인터넷에 잘 찾아보면 다른 사람이 올린 결과들이 많습니다. 특히 github이나 kaggle에요. 이렇게 논문을 보면서 2년이라는 시간이 흘렀고 가끔 운좋게 건진 논문의 결과도 보면 data를 2 대 8로 나눈 세트에서  아니면 random sampling 해서 나온 결과는 정말 테스트에서 기가막히게 나오는 것들도 많이 봤습니다. 하지만 test 셋을 반대로 8 대 2 아니면 그 이하로 5 대 5로 나누면 결과는 반대로 바뀝니다. random sampling, cross validation...도 마찬가지 입니다. 왜 이렇게 하냐고 물으시면 jane street 등 여러 실질적인 퀀트펌에서 종사하시는 분들이 나오서 podcast 하는 채널이 있습니다. https://www.youtube.com/channel/UCdnzT5Tl6pAkATOiDsPhqcg 여기서 공통되게 말하는게 금융에서는 테스트 셋을 2 대 8로 절대 나누면 안되고 오히려 반대로 나눠서 실행을 해봐야 하고 또한 모델을 학습 시킨 뒤 테스트 결과를 봐도 일정한 텀을 두고 학습 모델을 가지고 있다가 텀이 지나면 테스트를 하는 것 입니다. 쉽게 말해서 데이터를 삼등분 하되 학습하는데 가장 적은 샘플을 두는 것 입니다. 이렇게 통과된 모델은 시간이 지나도 알파가 유지가 된다고 합니다. 제가 염려를 하는 점이 바로 이 점 입니다. 모델링은 정말 잘하셨습니다. 기대가 되고요. 근데 평가모델이 잘못된거 같습니다. 만약에 제가 제시한 것으로 평가를 했을 때 통과 되었다고 하면 저도 믿고 etf 두둑히 챙기겠습니다.


K-fold CV 이야기하시는 것 같은데, 저도 그냥 라이브 이후 트랙레코드로 판단할 것 같습니다.

하고싶은 말이 많은 글이지만. 전문가분들이 답을 주실테니 전 이만… (몇대몇으로 나누냐 하는건 별로 의미가 없습니다. 백데이터 과적합은 어떻게 하든 발생하고 위험합니다. 인터넷의 자료들과 많은 논문들은 이런 과적합에 빠져있습니다. 이건 사실 과학적 사기라고 생각하고요. 수익은 sample이 아니라 oos에서 나오니까요. 과적합된 정도를 측정하기 위한 논문을 많이 읽어보시는걸 추천합니다.)


혹시 시스템트레이딩 기초를 쌓을때 보기 좋은 책 추천해주실수있나요??
https://www.youtube.com/watch?v=DW9zQ8Hz6gQ&feature=youtu.be


제가 여태 읽은 거 중 가장 흥미로운 거 쉐어할게요 시뮬레이션 trial 횟수마다 Sharpe ratio는 증가 할 수 밖에 없다 그러하니 높은 sharpe ratio 논문들이 실전에서는 안되는 것. 왜냐하면 해당 모델을 찾기까지 얼마나 많은 trial을 했는지 알 수 없다 단 통상적으로 샤프레시오가 5를 초과 하는 건 실전에 한번 써먹을수 있겠다 입니다


out of sample이 training set과 test set을 분리해서 튜닝/백테스팅을 따로 진행하는 걸 말씀하시는 건가요? 규칙 기반이라 그렇게 해 볼 생각은 못했는데 오늘 한 번 시도 해보겠습니다 ^^;;

변동성 돌파 전략.
https://post.naver.com/viewer/postView.nhn?volumeNo=15975365&memberNo=40921089
