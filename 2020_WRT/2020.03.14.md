

# TIL

구글 브레인의 최신 AutoML

레이어 단위로 블록을 만들었던 기존 AutoML의 수준을 수학 연산단위로 쪼개어, 머신 러닝의 세부적인 옵션까지도 자동적으로 선택하게 한 알고리즘입니다..

과연 구글브레인스러운 연구.. 이 정도면 진짜 스카이넷 드립 나올지도....

결론 ES로 밑바닥부터 ML 알고리즘 탐색해도 backprop쓰는 two-layer NN 이 발견되고 뒤이어 normalized gradient, weight averaging등도 나온다는.... 데이터 부족하면 drop-out 도...

좀더 자세히 읽어봐야 겠습니다 ㅎㅎ
https://arxiv.org/abs/2003.03384



AutoML-Zero：Evolving Machine Learning Algorithms From Scratch Review (HOYA012'S RESEARCH BLOG)

AutoML은 Machine Learning을 Automatic하게 수행하는 과정을 의미하며 지난 NASNet 논문 리뷰 포스팅 에서 간단히 소개 드린 바 있습니다. AutoML을 다룬 연구는 짧은 시간 동안 굉장히 많은 발전을 이뤘습니다. 대표적인 Neural Architecture Search(NAS)는 처음 제안된 방법은 수백개의 GPU로 몇 달을 돌려야 CIFAR-10에 대한 architecture 하나를 구할 수 있었는데, 이제는 하나의 GPU로 몇 시간만에 사람이 설계한 architecture의 성능을 뛰어넘고, 나아가 hardware에 최적화된, 즉 연산량, throughput까지 고려한 architecture를 자동으로 찾아내주기도 합니다.

즉, AutoML이라고 부르긴 했지만 실제론 어느 정도 사람이 개입하여야 했고, 대표적인 사례가 바로 search space 입니다. Architecture search를 예로 들면 각 layer에 1x1 conv, 3x3 conv, 3x3 max pooling 등 여러 옵션을 먼저 사람이 정해 놓은 뒤 search algorithm을 통해 architecture를 설계하는 방식이죠. 이렇게 AutoML은 아직까지 사람이 디자인해야 하는 요소가 남아있었는데 본 논문은 좀더 혁신적인 AutoML로 가기 위해선 전체 ML 알고리즘을 설계하는 과정에서 사람의 개입을 최소화 해야 한다고 역설하고 있습니다.

* 출처 : https://hoya012.github.io/blog/automl-zero-review/


퀀티와이즈 제대로 설치 안되어있는듯 하다.
http://corp.fnguide.com/fng/serviceinfo_quantiwiseIndex.fng